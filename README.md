# ü§ñ Clasificaci√≥n Autom√°tica con LLMs

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Sistema completo para clasificaci√≥n autom√°tica de **textos** e **im√°genes** utilizando modelos de lenguaje grandes (LLMs):

- **OpenAI GPT-4o-mini** - Para clasificaci√≥n de texto
- **Ollama** con modelos de visi√≥n - Para clasificaci√≥n de im√°genes

## üìã Caracter√≠sticas

- ‚úÖ Clasificaci√≥n de texto con OpenAI
- ‚úÖ Clasificaci√≥n de im√°genes con Ollama (modelos locales)
- ‚úÖ Procesamiento por lotes de directorios completos
- ‚úÖ Soporte para m√∫ltiples formatos de imagen
- ‚úÖ Sistema de verificaci√≥n autom√°tica
- ‚úÖ Ejemplos interactivos incluidos
- ‚úÖ Documentaci√≥n completa

## üöÄ Inicio R√°pido

### 1. Instalaci√≥n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/clasificacion-llms.git
cd clasificacion-llms

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Configuraci√≥n

**Para clasificaci√≥n de texto (OpenAI):**
```bash
# Copiar plantilla de configuraci√≥n
cp .env.example .env

# Editar .env y a√±adir tu API key de OpenAI
# OPENAI_API_KEY=tu-api-key-aqui
```

Obt√©n tu API key en: https://platform.openai.com/api-keys

**Para clasificaci√≥n de im√°genes (Ollama):**
```bash
# Instalar Ollama (visita https://ollama.ai para instrucciones)

# Iniciar servidor
ollama serve

# Instalar modelo de visi√≥n (en otra terminal)
ollama pull gemma3:27b-it-qat
```

### 3. Verificar Instalaci√≥n

```bash
python check_installation.py
```

Este script verifica:
- ‚úÖ Versi√≥n de Python
- ‚úÖ Dependencias instaladas
- ‚úÖ Configuraci√≥n de APIs
- ‚úÖ Servidor Ollama (si aplica)

## ÔøΩ Uso

### Clasificaci√≥n de Texto con GPT-4o-mini

1. Aseg√∫rate de tener el archivo `prompt_18.txt` en el directorio
2. Configura tu API key de OpenAI
3. Ejecuta el script:
   ```bash
   python classify_with_gpt.py
   ```

El script cargar√° el dataset, clasificar√° las frases y generar√° m√©tricas de evaluaci√≥n.

### Clasificaci√≥n de Im√°genes con Ollama

#### Opci√≥n 1: Uso Interactivo
```bash
python classify_images_with_ollama.py
```

El script te guiar√° para:
- Verificar la conexi√≥n con Ollama
- Seleccionar un directorio con im√°genes
- Procesar todas las im√°genes del directorio

#### Opci√≥n 2: Uso Program√°tico

```python
from classify_images_with_ollama import OllamaImageClassifier

# Crear clasificador
classifier = OllamaImageClassifier(
    model_name="gemma3:27b-it-qat",
    ollama_url="http://localhost:11434"
)

# Verificar conexi√≥n
if classifier.check_connection():
    
    # Clasificar una sola imagen desde archivo local
    prompt = """Describe this image in detail, identifying the main subject, 
    setting, and notable features."""
    
    result = classifier.classify_single_image(
        image_source="path/to/image.jpg",
        prompt=prompt,
        is_url=False
    )
    print(result)
    
    # Procesar un directorio completo
    results = classifier.process_directory(
        directory_path="images_folder",
        prompt=prompt,
        output_file="results.json"
    )
```

#### Opci√≥n 3: Clasificar desde URL

```python
from classify_images_with_ollama import OllamaImageClassifier

classifier = OllamaImageClassifier()

# Clasificar imagen desde URL
result = classifier.classify_single_image(
    image_source="https://example.com/image.jpg",
    prompt="Describe this image",
    is_url=True
)
```

## üìä Resultados

### Clasificaci√≥n de Texto
El script genera:
- Precisi√≥n, recall, F1-score
- Matriz de confusi√≥n
- Reporte de clasificaci√≥n detallado
- Archivo CSV con resultados

### Clasificaci√≥n de Im√°genes
El script genera:
- Archivo JSON con resultados de cada imagen
- Resumen en consola con estad√≠sticas
- Timestamp de procesamiento
- Manejo de errores por imagen

Ejemplo de salida JSON:
```json
[
    {
        "file": "image1.jpg",
        "path": "/full/path/to/image1.jpg",
        "classification": "Detailed description...",
        "error": null,
        "timestamp": "2025-10-30 14:32:15"
    }
]
```

## üéØ Personalizaci√≥n de Prompts

### Para Im√°genes

Puedes crear prompts personalizados seg√∫n tu necesidad:

```python
# Prompt para clasificaci√≥n de objetos
object_prompt = """Identify all objects in this image.
List them in order of prominence.
For each object, provide:
- Name
- Location in image
- Estimated size relative to image
- Color

Respond in JSON format."""

# Prompt para an√°lisis de sentimiento visual
sentiment_prompt = """Analyze the emotional tone of this image.
Consider:
- Facial expressions (if any)
- Color palette
- Composition
- Lighting

Rate the emotional valence from 1-10 (1=negative, 10=positive)
and arousal from 1-10 (1=calm, 10=exciting).

Respond in JSON format with: valence, arousal, description"""
```

Consulta [ADVANCED_PROMPTS.md](ADVANCED_PROMPTS.md) para m√°s ejemplos especializados.

## üîÑ Procesamiento por Lotes

```python
from classify_images_with_ollama import OllamaImageClassifier

classifier = OllamaImageClassifier()
directories = ["dir1", "dir2", "dir3"]
prompt = "Describe this image briefly"

for dir_path in directories:
    results = classifier.process_directory(
        directory_path=dir_path,
        prompt=prompt,
        output_file=f"{dir_path}_results.json"
    )
```

## üõ†Ô∏è Soluci√≥n de Problemas

| Problema | Soluci√≥n |
|----------|----------|
| **Ollama no conecta** | Ejecuta `ollama serve` y verifica con `ollama list` |
| **Modelo no encontrado** | Instala el modelo: `ollama pull gemma3:27b-it-qat` |
| **Error de memoria** | Las im√°genes se optimizan autom√°ticamente. Reduce el tama√±o si persiste |
| **OpenAI timeout** | Verifica tu conexi√≥n e API key. Hay 3 reintentos autom√°ticos |
| **Dependencias faltantes** | Ejecuta `python check_installation.py` para diagn√≥stico |

## ÔøΩ Documentaci√≥n Adicional

- **[QUICKSTART.md](QUICKSTART.md)** - Gu√≠a de inicio r√°pido en 3 pasos
- **[ADVANCED_PROMPTS.md](ADVANCED_PROMPTS.md)** - 15+ ejemplos de prompts especializados
- **[check_installation.py](check_installation.py)** - Script de verificaci√≥n del sistema
- **[example_usage.py](example_usage.py)** - Ejemplos interactivos

## üîí Seguridad

- ‚ö†Ô∏è **Nunca subas tu `.env` con API keys al repositorio**
- ‚úÖ Usa `.env.example` como plantilla
- ‚úÖ Las API keys deben estar en variables de entorno
- ‚úÖ Revisa el `.gitignore` antes de hacer commit

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Para contribuir:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## ÔøΩ Agradecimientos

- [Ollama](https://ollama.ai) por proporcionar modelos de visi√≥n locales
- [OpenAI](https://openai.com) por su API de clasificaci√≥n de texto
- Comunidad open source por las herramientas y librer√≠as

## üìû Soporte

- üêõ **Issues**: [GitHub Issues](https://github.com/tu-usuario/clasificacion-llms/issues)
- üìñ **Documentaci√≥n**: Ver archivos `.md` en el repositorio
- üí¨ **Discusiones**: [GitHub Discussions](https://github.com/tu-usuario/clasificacion-llms/discussions)
